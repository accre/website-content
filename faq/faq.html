<div id="top"/>

<div id="cluster-accounts" class="section level4">
<h4>Cluster Accounts:</h4>
<ul>
<li><p><a href="#password">How do I change my ACCRE account password?</a></p></li>
<li><p><a href="#forgotpassword">I've forgotten my password; what is the procedure to reset it?</a></p></li>
<li><p><a href="#hadoopaccess">Does ACCRE have a Hadoop cluster that includes tools like HDFS, MapReduce, Spark, Hue, Hive, Impala, and so on?</a></p></li>
</ul>
</div>
<div id="connectivity" class="section level4">
<h4>Connectivity:</h4>
<ul>
<li><p><a href="#logonsystemhang">I cannot connect to the cluster, am experiencing intermittent connectivity to the cluster, or the system hangs upon log on. What should I do?</a></p></li>
<li><p><a href="#dnscache">I cannot connect to <code>login.accre.vanderbilt.edu</code> or after logging in got an error message says my home directory is not found.</a></p></li>
<li><p><a href="#down_time">How can I make a scheduled downtime work for me?</a></p></li>
<li><p><a href="#samba_mounting">How can I mount a Samba (<code>smb</code>) share?</a></p></li>
</ul>
</div>
<div id="configuring-your-environment" class="section level4">
<h4>Configuring your Environment:</h4>
<ul>
<li><p><a href="#changeshell">How do I change my default shell?</a></p></li>
<li><p><a href="#xremotedisplay">How do I display graphics from the cluster to my local machine?</a></p></li>
<li><p><a href="#xauthority">I am running an X server, how do I fix X connection or .Xauthority file errors?</a></p></li>
</ul>
</div>
<div id="linux" class="section level4">
<h4>Linux:</h4>
<ul>
<li><p><a href="#linuxcommand">What command do I need to type in order to run an executable in Linux?</a></p></li>
<li><p><a href="#chgrp">How do I change the group associated with a file or directory?</a></p></li>
</ul>
</div>
<div id="submitting-and-running-jobs-also-read-getting-started" class="section level4">
<h4>Submitting and Running Jobs (Also read <a href="/?page_id=303" title="Getting Started">Getting Started</a>):</h4>
<ul>
<li><p><a href="#nodes">What types of nodes are available?</a></p></li>
<li><p><a href="#testcluster">How do I run test jobs?</a></p></li>
<li><p><a href="#pbs_node_attributes">What are the ACCRE cluster defined attributes I can use in my SBATCH scripts corresponding to the available node properties?</a></p></li>
<li><p><a href="#gateways">Can I run on the gateway machines?</a></p></li>
<li><p><a href="#resourcekill">What happens if my job uses more resources than requested?</a></p></li>
<li><p><a href="#longwaittime">Why is my eligible job waiting so long in the <em>Idle</em> state?</a></p></li>
<li><p><a href="#deferredjob">What does job status <em>Deferred</em> mean?</a></p></li>
<li><p><a href="#maxjoblimits">What is the maximum number of jobs I can submit or have running at any one time?</a></p></li>
<li><p><a href="#maxjobtime">What is the maximum allowed &quot;wall clock time&quot; I may specify?</a></p></li>
<li><p><a href="#torque">How do I hold/release/delete a job?</a></p></li>
<li><p><a href="#moabcommands">Where can I find detailed documentation on all SLURM Commands?</a></p></li>
<li><p><a href="#deletejobs">How can I delete many jobs at once?</a></p></li>
<li><p><a href="#memorysize">How much memory is available on each node?</a></p></li>
<li><p><a href="#requestwholenode">How do I request all the processor cores in a node?</a></p></li>
<li><p><a href="#eightcore">How do I request an 8-core node for exclusive usage?</a></p></li>
<li><p><a href="#determinewholenode">How can I determine whether or not I have all the processor cores in a node assigned to my job (and why would I want to do so)?</a></p></li>
<li><p><a href="#multiplegroups">If I belong to multiple groups, how can I define the group name under which my job is to run on the cluster?</a></p></li>
<li><p><a href="#checkpoint">How do I checkpoint my job?</a></p></li>
<li><p><a href="#localstorage">How do I use local storage on a node?</a></p></li>
<li><p><a href="#sockettimeout">My job submission fails with a socket timeout message. What's the problem?</a></p></li>
</ul>
</div>
<div id="disk-space" class="section level4">
<h4>Disk Space:</h4>
<ul>
<li><p><a href="#disk_usage">How can I determine my disk space quota and how much disk resources I am using?</a></p></li>
<li><p><a href="#dors_usage">My group has storage on DORS. How can I check our usage?</a></p></li>
<li><p><a href="#scratch_disk">I need a lot of disk space for temporary use. How do I make use of the /scratch space?</a></p></li>
<li><p><a href="#tempquota">If I need more disk space than this, will you temporarily grant a quota increase?</a></p></li>
<li><p><a href="/?page_id=72">What if I need more disk space than the default quota limits on /home and /scratch for an extended period of time? <em>(Links to our disk policies page)</em></a></p></li>
<li><p><a href="#restoredata">Will ACCRE restore deleted or lost data?</a></p></li>
<li><p><a href="#copydata">My network connection to ACCRE is really poor and I have a lot of data that I need to upload to ACCRE (or download from ACCRE). What are my options?</a></p></li>
</ul>
</div>
<div id="gpu" class="section level4">
<h4>GPU:</h4>
<ul>
<li><a href="#gpu_submit">How do I request a gpu node?</a></li>
</ul>
</div>
<div id="software-and-compiling" class="section level4">
<h4>Software and Compiling:</h4>
<ul>
<li><p><a href="#software_current">What research software packages are available on the cluster?</a></p></li>
<li><p><a href="#usr_env">How do I make sure that my perl/python script is using the latest version available on the cluster?</a></p></li>
<li><p><a href="#software_install">I'd like to have some software installed on the cluster. How do I go about doing that?</a></p></li>
<li><p><a href="#R_install_source">How do I install an R package from source code?</a></p></li>
<li><p><a href="#R_install_internet">How do I download and install an R package from the internet?</a></p></li>
<li><p><a href="#R_install_bioconductor">How do I install and load an R package from Bioconductor?</a></p></li>
<li><p><a href="#perl_module_install">How do I install a perl module without root privilege?</a></p></li>
<li><p><a href="#python_check_packages">How do I check which python packages are installed?</a></p></li>
<li><p><a href="#python_module_install">How do I install a python package from source code?</a></p></li>
<li><p><a href="#matlab_sas_license">How do I run Matlab/SAS job on the cluster?</a></p></li>
</ul>
<hr />
<div id="password" class="section level6">
<h6>Accounts: How do I change my ACCRE account password?</h6>
<p>Please follow these steps:</p>
<ol style="list-style-type: decimal">
<li>Log on to the cluster (<code>login.accre.vanderbilt.edu</code>) using your existing password. At this point you are simply logged on to a cluster gateway. Any changes to your account will need to be propogated to all of the compute nodes.</li>
<li>Issue the command: <code>rsh auth</code>. Commands issued now (e.g., the <code>passwd</code> command below) will affect modifications to all of the nodes.</li>
<li>To change your password, type the command <code>passwd</code>. The <code>passwd</code> program will prompt you to enter a new password. Please use a non-dictionary word (i.e., nonstandard words, combinations of letters and numbers). After you have changed your password, <strong>please allow approximately 20 minutes for the change to be propogated to all of the nodes</strong>.</li>
<li>To disconnect from <code>auth</code>, type <code>exit</code>. You will still be logged into your account. You may either continue working on the cluster or log out.</li>
</ol>
<p><strong>See also our tutorials on <a href="/?page_id=303">getting started on the cluster</a>.</strong></p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="forgotpassword" class="section level6">
<h6>Accounts: I've forgotten my password or my password has expired; what is the procedure to reset it?</h6>
<p>Notify us by submitting a <a href="/?page_id=369">Request Tracker</a> ticket. The script we run to reset your password propagates the change out to the cluster and sends you e-mail with your new password. This normally takes a few minutes, and we ask you wait at least 15 minutes to log on. As soon as you receive the e-mail with your new password, please follow <a href="#password"><strong>the procedure to reset it to something of your choosing</strong></a>.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="hadoopaccess" class="section level6">
<h6>Does ACCRE have a Hadoop cluster that includes tools like HDFS, MapReduce, Spark, Hue, Hive, Impala, and so on?</h6>
<p>Yes! Open a help desk ticket requesting (free) access. You can find more information about the environment in <a href="https://my.vanderbilt.edu/universityfundingprograms/2017/01/update-on-a-trans-institutional-big-data-infrastructure-at-vanderbilt/">this blog post</a> and in our <a href="https://github.com/bigdata-vandy">Vanderbilt Big Data GitHub Organization</a>. We currently have a development environment set up for Vanderbilt and VUMC researchers to access, and plan to build out a production environment over the next 2-3 years.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="logonsystemhang" class="section level6">
<h6>Connectivity: I cannot connect to the cluster, am experiencing intermittent connectivity to the cluster, or the system hangs upon log on. What should I do?</h6>
<p>If you are normally able to connect and suddenly cannot, let us know via <a href="/?page_id=369">Request Tracker</a>. Please provide as much information about the issue as possible including any useful output to your screen. Besides occasional network problems, there are a number of possible causes for sluggish to zero connectivity. Please read the following to help self-diagnose before submitting a help desk ticket so we are better able to assist you:</p>
<ul>
<li>You may connect to the cluster only via a Secure Shell (<strong>SSH</strong>) client. For more information go to <a href="/?page_id=326">Logging on to the Cluster</a>.</li>
<li>If you see the following error when trying to connect: <code>ssh: connect to host login.accre.vanderbilt.edu port 22: Operation timed out</code> it means the gateway you're trying to connect to is unreachable.The cluster has roughly 20 x86 gateway machines (See <a href="/?page_id=63#nodes">node configuration</a> ). There are several reasons why we have multiple gateways of each architecture. For example, this distributes the user load across many login gateways. Another main reason is to protect against an unreachable gateway preventing a connection to the cluster.However, even with this backup system in place it is still possible when you ssh to <code>login.accre.vanderbilt.edu</code> to get an error similar to the above. <code>login</code> is only an alias which uses DNS round-robining to select one of the actual gateway machines to connect to. If you get the above error, what has likely happened is that either the local DNS cache on your system or the DNS server you use has cached an alias to a gateway which is now unreachable for some reason. If this occurs, you should simply select one of the actual gateways at random and attempt to ssh directly to it. For example, <code>ssh vmps65.accre.vanderbilt.edu</code>.</li>
<li>If you can connect but the connection &quot;hangs&quot; before you receive a command-line prompt, your problem may be related to an error in one of your login files (e. g., .bashrc in your home directory). This we can help diagnose. Please send us a message via <a href="/?page_id=369">Request Tracker</a>.</li>
<li>If you can connect but your login &quot;hangs&quot;, it is possible we are experiencing a problem with <a href="http://www-03.ibm.com/systems/clusters/software/gpfs.html">GPFS</a> (the General Parallel File System designed by IBM). Other symptoms of this include logging on but not being able to see, for example, your home directory. Sometimes the file system problem is temporary, lasting only a moment. Larger file system problems normally occur when the system is overloaded, which can happen for various reasons. If the problem is found to be caused by a particular user account or set of jobs, we immediately work with the user to resolve it.Sometimes the issue is not related to user software or the way a user is submitting jobs and we have to work with IBM to determine the root of the file system problem. When we expect the issue cannot be resolved quickly we notify all users to expect intermittent cluster access.In most cases when the system is in this state you should still be able to accomplish your work, albeit you may find the system is occasionally sluggish and intermittently nonresponsive. Please be patient. You will find upon repeated attempts you will be able to log on and submit jobs. If these jobs are not heavily dependent on disk I/O they should continue running.</li>
</ul>
<p>In any case, so we can immediately begin resolving the issue, please notify us ASAP of any connectivity problems by submitting a <a href="/?page_id=369">Request Tracker</a> ticket. Include details such as a &quot;cut and paste&quot; of the information in your login window if you are able.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="dnscache" class="section level6">
<h6>Connectivity: I cannot connect to <code>login.accre.vanderbilt.edu</code> or after logging in got an error message says my home directory is not found</h6>
<p><code>login.accre.vanderbilt.edu</code> is a DNS round robin alias for one of our ~6 cluster gateways. It is possible that the gateway you were randomly assigned is experiencing a hardware issue. When this happens we take the gateway out of the rotation but DNS may cache the old information for a period of time. Please open a help desk ticket for assistance.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="down_time" class="section level6">
<h6>Connectivity: How can I make a scheduled downtime work for me?</h6>
<p>As a scheduled downtime for the cluster approaches more time becomes available for shorter jobs. Thus, if you have applications that take a few days or less to run, you will be able to execute more of these types of jobs as a scheduled downtime approaches because applications requiring longer period of times will not be running. It's an excellent time to take advantage of the extra computing cycles that would ordinarily not be available!</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="samba_mounting" class="section level6">
<h6>Connectivity: How do I mount a Samba (<code>smb</code>) share?</h6>
<p>If you have been assigned a Samba or smb share to mount locally the following instructions should help. Note you should have been given a share name and you should have a Samba password that is different from your cluster or VUnetID password:</p>
<p><strong>On a Mac</strong> open finder. On the menu bar at the top select Go, Connect to Server... (⌘K). In the Server Address: field enter the following;</p>
<pre class="outline"><code>smb://samba.accre.vanderbilt.edu\*sharename*\</code></pre>
<p>where <code>sharename</code> is the name of the Samba share you were assigned. Next click Connect and you will be prompted for a Name and Password. This will be your cluster username and your Samba password. At this point hit Connect again and your share will be mounted as a drive in Finder.  </p>
<p><strong>On a Windows PC</strong> run File Explorer (from the start bar it will be a folder or you can hit the windows key and type in explorer). In the address bar at the top enter the following;</p>
<pre class="outline"><code>\\samba.accre.vanderbilt.edu\*sharename*\</code></pre>
<p>where <code>sharename</code> is the name of the Samba share you were assigned. Hit enter and you will be prompted for a username and password. Enter your cluster username and your Samba password and hit enter or click ok. At this point your share will be mounted as a drive in File Explorer.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="changeshell" class="section level6">
<h6>Environment: How do I change my default shell?</h6>
<p>Once you log onto the cluster (<code>login.accre.vanderbilt.edu</code>) , type: <code>rsh auth</code>. You are now on the authentication server. Type: <code>chsh</code>. You will be prompted for password. Enter the new shell you want to use. For bash, this is <code>/bin/bash</code>, for tcsh, <code>/bin/tcsh</code>. Type <code>exit</code> to log out of auth and then wait 20 minutes or so for the new setting be propagated throughout the cluster. Log onto the cluster again and you should see the change.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="xremotedisplay" class="section level6">
<h6>Environment: How do I display graphics from the cluster to my local machine?</h6>
<p>You need two things: (N. b., you should first check with your P. I. before installing the following software, since one or both of these may already be on your system, especially if you're using a computer in your lab which is already configured to run on the cluster)</p>
<ol style="list-style-type: decimal">
<li><strong>Get X server support on your local machine:</strong> The graphics environment on the cluster is X11, therefore, you must install and run an X server from your local machine</li>
<li><strong>Configure SSH tunneling:</strong> You must tell <strong>SSH</strong> on your local machine to allow the display of graphics from software running on the cluster.</li>
</ol>
<p><strong>Windows users:</strong> <a href="http://www.straightrunning.com/XmingNotes/">Xming X Server</a> is one of the best X Window servers available for Windows. You can follow the instruction provided there to install and set up the server. <strong>Mac OS X users:</strong> You can get a free <a href="http://xquartz.macosforge.org/landing/">X11 server from Apple</a>. Mac OS X should already have <strong>SSH</strong> installed.</p>
<ol style="list-style-type: decimal">
<li>Follow their directions to install and run the X11 server.</li>
<li>Launch the X11 server.</li>
<li>Run an <code>xterm</code>.</li>
<li>When you log on to the cluster from the command line in the xterm, to activate <strong>SSH</strong> tunneling you can use the <code>-X</code> option, i.e., <code>ssh -X user@login.accre.vanderbilt.edu</code>.</li>
<li>Finally, <a href="#checkx">see below</a> for how to quickly check you can display remote graphics locally.</li>
</ol>
<p><strong>Linux users:</strong> We assume you are already running an X server and have <strong>SSH</strong> installed.</p>
<ol style="list-style-type: decimal">
<li>When you log on to the cluster, <code>ssh -X</code> will activate <strong>SSH</strong> tunneling, i.e., <code>ssh -X user@login.accre.vanderbilt.edu</code>.</li>
<li><a href="#checkx">See below</a> for how to quickly check you can display remote graphics locally.</li>
</ol>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="xauthority" class="section level6">
<h6>Environment: I am running an X server, how do I fix X connection or .Xauthority file errors?</h6>
<p>If you are getting error messages similar to these:</p>
<pre class="outline"><code>/usr/X11R6/bin/xauth: error in locking authority file /home/user/.Xauthority</code></pre>
<pre class="outline"><code>X11 connection rejected because of wrong authentication. X connection to 
localhost:11.0 broken (explicit kill or server shutdown)</code></pre>
<p>try removing the <code>.Xauthority</code> file in your home directory, then log out and back in. This file occasionally becomes corrupted. When you log back in and start X, it will recreate your <code>.Xauthority</code> file. Sometimes you have to do this a few times. If you continue to have problems, please submit a <a href="/?page_id=369">Request Tracker</a> ticket.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="linuxcommand" class="section level6">
<h6>Linux: What command do I need to type in order to run an executable in Linux?</h6>
<p>To execute a program in the current work directory, type:</p>
<pre class="outline"><code>./&lt;file_name&gt;</code></pre>
<p>For files that are not in the current working directory, use the full path: <code>/path/to/your/executable/file</code></p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="chgrp" class="section level6">
<h6>Linux: How do I change the group associated with a file?</h6>
<p>You can change the group of a file if you are the file's owner and you are in the group to which you are trying to change the file. The command is:</p>
<pre class="outline"><code>chgrp [options] group_name file_name</code></pre>
<p><code>-R</code>: recurse through subdirectories <code>-f</code>: suppress most error messages If you want to submit a job from group other than your primary group, please see <a href="#multiplegroups">this FAQ</a>.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="nodes" class="section level6">
<h6>Jobs: What types of nodes are available?]</h6>
<p>We currently have nodes with between 8-16 CPU cores and 24-256GB RAM. We also have a group of nodes equipped with modern NVIDIA GPUs and a small set of nodes with Intel Xeon Phi accelerators on board. Please refer to our <a href="http://www.accre.vanderbilt.edu/?page_id=377">Intro to the Cluster slides</a> for more details.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="testcluster" class="section level6">
<h6>Jobs: How do I run test jobs?</h6>
<p>We allow users to run very short (&lt; 5 minutes) tests that have low memory usage (&lt; 1 GB). Anything more should be submitted the scheduler. We have a <a href="http://www.accre.vanderbilt.edu/?page_id=2154#torque">debug SLURM partition/queue</a> available for running quick tests and prototyping.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="pbs_node_attributes" class="section level6">
<h6>Jobs: What are the ACCRE cluster defined attributes I can use in my SBATCH scripts corresponding to the available node properties?</h6>
<p>The properties of our <a href="/?page_id=63#nodes">compute nodes</a> can be specified with combinations of available attributes (defined by us), e.g.: <code>haswell, sandy_bridge, eight</code> Note that the <code>haswell</code> attribute requests the latest Intel processors, while <code>sandy_bridge</code> requests the previous generation. The <code>eight</code> attribute requests nodes that only have eight processors, and the scheduler will avoid placing the job on the 12-core nodes. In your batch script you could specify: <code>#SBATCH --constraint=haswell</code>. This would instruct the scheduler to run the job only on a node with an Intel Xeon Haswell processor. Note that your job may take longer to start when these attributes are included as you are limiting the pool of resources the scheduler can choose from. For a full list of available features, trying running the <code>sinfofeatures</code> command while logged into the cluster. Find more examples in subsequent <a href="#pbs_nodes">FAQ</a>.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="gateways" class="section level6">
<h6>Jobs: Can I run on the gateway machines?</h6>
<p>When you log on via <code>login.accre.vanderbilt.edu</code>, you are logged onto a gateway machine. From here you submit your jobs which are sent to the compute nodes by the scheduler. However, we do allow you to run very short, &lt; 5 minute, test jobs on the gateway machines, as long as such jobs do not slow the gateway for other users. Anything longer than this should be submitted to the compute nodes using <code>batch</code> (see <a href="/?page_id=343">How to Submit Basic Jobs</a>).</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="resourcekill" class="section level6">
<h6>Jobs: What happens if my job uses more resources than requested?</h6>
<p>The job scheduler will automatically kill most jobs which exceed the resources requested in the SBATCH script. For example, if you specify a <code>walltime</code> of 4 hours and your job runs over that, the scheduler will kill the job. The reason for this is that running jobs which use more resources than requested may affect the scheduling and running of other jobs. This is because the scheduler relies on SLURM specifications (among other parameters) to determine on which nodes to run jobs. Also read our <a href="/?page_id=89">job scheduler policies</a> for more information on killing jobs which are interfering with other jobs or the system itself. When testing code or running code you are unfamiliar with, you should more diligently monitor the resource consumption to fine tune your SBATCH request. Specifying much more, e.g., <code>walltime</code> or <code>mem</code>, than your job requires may delay its start time if the requested resources are not immediately available. Therefore, you should start somewhat conservatively, then reduce your resource specifications once you've determined what you are really using, still always leaving a buffer to ensure the job is covered. Learn more about how to request resources and the SBATCH defaults <a href="/?page_id=343">when you submit a job</a>. Learn how to <a href="/?page_id=361">monitor and check the status of a submitted job</a>.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="longwaittime" class="section level6">
<h6>Jobs: Why is my eligible job waiting so long in the <em>PENDING</em> state?</h6>
<p>There are several things you should check to understand your wait time in the queue. See <a href="/?page_id=343">tips on checking the status of a submitted job</a>.</p>
<ul>
<li><strong>Make sure you have requested an allowed set of resources.</strong> Check your SBATCH script against both the <a href="/?page_id=63#nodes">available nodes</a> in the cluster and our <a href="/?page_id=89">job scheduler policies</a>. You can also check on the resources requested with the command: <strong>scontrol show job</strong> <em>job_number</em></li>
<li>Check your group's current usage by typing <code>qSummary -g group_name</code>. Compare that to your group's bursting limits by running <code>showLimits -g group_name</code>. If your group's current usage is close to or equal to its bursting limits, this could be causing delays. Details about both of these commands can be found <a href="http://www.accre.vanderbilt.edu/?page_id=2154#accrecommands">by clicking on this link</a>.</li>
<li>Check overall cluster utilization with the <a href="http://www.accre.vanderbilt.edu/?page_id=2154#SlurmActive"><code>SlurmActive</code></a> command.</li>
<li>Check the queue and current usage on the cluster. It could be the particular resources your jobs need may be heavily utilized, even if the entire cluster is not. You can check the total usage of the cluster with the command <code>squeue</code>. You can also see current and past <a href="/?page_id=767">utilization</a> levels on this website.</li>
<li><p>Your account or group account may be running over its fairshare. This means when the cluster is very busy, other jobs from accounts which are under fairshare may be assigned higher priority and may jump ahead of your job in the eligible queue. Use the</p>
<pre class="outline"><code>sacctmgr show associations Accounts=account_name \
  format=account%30,user%30,fairshare,grpcpus,grpmem</code></pre>
<p>command to check your fairshare.</p></li>
</ul>
<p>If you still do not understand why your jobs are not starting more quickly, please submit an <a href="/?page_id=369">RT ticket</a>.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="deferredjob" class="section level6">
<h6>Jobs: What does job status <em>Deferred</em> mean?</h6>
<p>In slurm there is no &quot;deferred&quot; state. However, jobs may ask for resources that cannot be provided, e.g., too much memory. In such cases, running the command squeue and looking for your jobib, slurm will provide a short explanation of why the job either cannot run, or is not running. Do <code>squeue -u &lt;username&gt;</code> to see the explanation.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="maxjoblimits" class="section level6">
<h6>Jobs: What is the maximum number of jobs I can submit or have running at any one time?</h6>
<p><strong>&quot;Active&quot; Limits:</strong> Each user/group/account has a limit on the number of processors in use at any time. This number is summed from any combination of single and multi-processor jobs. Additional limits are placed as necessary for groups running either medium (defined as 4 to 7 days) or long (over 7 days) jobs on a regular basis if there usage is impacting the ability of other groups to use their full fairshare. Individual groups may also request upper limits on their users. New guest users have upper job limits until they have attended the <a href="/?page_id=377">Introduction to the Cluster and Job Scheduler classes</a>. Use the <a href="http://www.accre.vanderbilt.edu/?page_id=2154#showLimits"><code>showLimits</code></a> command to check your group's limits. Please refer to the <a href="/?page_id=89">job scheduler policies</a> for additional important details of these limits.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="maxjobtime" class="section level6">
<h6>Jobs: What is the maximum allowed &quot;wall clock time&quot; I may specify?</h6>
<p>The maximum allowed walltime is <strong>14 days</strong>, or in <strong>hh:mm:ss = 336:00:00</strong>. Your job will not start if you have specified a walltime greater than this. You may reduce the walltime of an already submitted job <a href="#editjobtime">using <code>scontrol</code></a> (slurm job control). In addition we ask that, except for a small number of test jobs, jobs run at least 30 minutes and over an hour in length is preferable. Our <a href="/?page_id=89">job scheduler policies</a> explains more on this subject. Also see <a href="/?page_id=343">How to Submit Basic Jobs</a> for other SBATCH specifications and how to deal with very short jobs.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="torque" class="section level6">
<h6>Jobs: How do I hold/release/delete a job?</h6>
<p>A user may place a USER hold upon any job the user owns. To do that, type: <code>scontrol hold &lt;jobId&gt;</code>. To release the held job, type: <code>scontrol release &lt;jobId&gt;</code>. Note that you can only hold and release jobs that are pending (i.e. this will not work for running jobs). User can also delete a queued/running job using the command: <code>scontrol resume &lt;jobId&gt;</code>. To delete all the jobs owned by the user, type: <code>scancel -u &lt;userid&gt;</code>. To cancel a job by name, type: <code>scancel --name &lt;jobName&gt;</code>.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="moabcommands" class="section level6">
<h6>Jobs: Where can I find detailed documentation on all SLURM commands?</h6>
<p>Please visit <a href="www.schedmd.com" class="uri">www.schedmd.com</a> for a complete and detailed list of all slurm commands.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="deletejobs" class="section level6">
<h6>Jobs: How can I delete many jobs at once?</h6>
<p>If you are using bash, the following script shows how to delete all jobs between 10000 and 10010:</p>
<pre class="outline"><code>    for jobid in `seq 10000 10010`
    do
    scancel $jobid
    echo cancelling $jobid
    done</code></pre>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="memorysize" class="section level6">
<h6>Jobs: How much memory is available on each node?</h6>
<p>Because the OS and other system processes (e.g. GPFS managment) already use certain amount of memory, not all physical memory is avaiable for running jobs. In general, ACCRE nodes contain anywhere from 22GB - 248GB of available memory for jobs to use.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="requestwholenode" class="section level6">
<h6>Jobs: How do I request all the processor cores in a node?</h6>
<p>Since the cluster has some nodes with 8 cores (2 x quad-core processors) and some with 12 cores (2 x hex-core processors) there is no way to generically request all the cores in a node. You can control whether your job lands on a 8-core or 12-core node; however, there is no <code>SBATCH</code> directive which effectively says, &quot;Give me all the cores in the node no matter how many there are.&quot; If your SBATCH script has <code>SBATCH -n 8</code> asking for 8 cores, your job could land on either an 8 or 12 core node; including the attribute <code>eight</code> will ensure your job is run on a 8-core node (see the next FAQ). If your SBATCH script has <code>SBATCH -n 12</code> your job will only land on a 12 core node. However, this might increase your wait time in the queue as there are currently more 8-core nodes than 12-core nodes in the cluster.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="eightcore" class="section level6">
<h6>Jobs: How do I request an 8-core node for exclusive usage?</h6>
<p>To request an 8-core node exclusively, your can now use:</p>
<pre class="outline"><code>#SBATCH -n 8 
#SBATCH --constraint=&quot;eight&quot;` </code></pre>
<p>in your job submission script. If the job does not require exclusive access to the node (it just needs 8 cores), you can still use:</p>
<pre class="outline"><code>#SBATCH -n 8</code></pre>
<p>Note that in this case, the job can be assigned to an 8-core node (exclusively) or a 12-core node that is shared with other jobs. You can do something similar for the 12-core and 16-cores compute nodes.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="determinewholenode" class="section level6">
<h6>Jobs: How can I determine whether or not I have all the processor cores in a node assigned to my job (and why would I want to do so)?</h6>
<p>As mentioned above, if your SBATCH script asks for 8 cores your job could land on either an 8 or 12 core node. Intel CPUs support hyperthreading, which essentially allows each physical core to appear to be two cores. Many multi-processor applications can take advantage of hyperthreading to run in significantly less time. Please see <a href="http://www.intel.com/content/www/us/en/architecture-and-technology/hyper-threading/hyper-threading-technology.html" class="uri">http://www.intel.com/content/www/us/en/architecture-and-technology/hyper-threading/hyper-threading-technology.html</a> for more information on hyperthreading.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="multiplegroups" class="section level6">
<h6>Jobs: If I belong to multiple groups, how can I define the group name under which my job is to run on the cluster?</h6>
<p>You can add the following line in your SBATCH script: <code>#SBATCH --account=&lt;mygroup&gt;</code>. Here, <code>mygroup</code> is the group name that you want the job to run under. To change group associated with a file, please see <a href="#chgrp">this FAQ</a>.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="checkpoint" class="section level6">
<h6>Jobs: How do I checkpoint my job?</h6>
<p>If your job runs more than a few hours, it is a good idea to periodically save output to disk in case of failure. There are also tools such as <a href="https://ftg.lbl.gov/projects/CheckpointRestart/">Berkeley Lab Checkpoint/Restart (BLCR)</a> that provide supports for kernel/user level checkpoint/restart.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="localstorage" class="section level6">
<h6>Jobs: How do I use local storage on a node?</h6>
<p>In some scenarios it may be advantageous to read or write data to a compute node's local hard disk, rather than to/from our parallel filesystem (<code>/home</code>, <code>/scratch</code>, and <code>/data</code> are all stored on the parallel filesystem). One common example is if you will be reading or writing to/from a file frequently. Each compute node has a world-readable/writeable directory at <code>/tmp</code>. If you want to move files to this local storage, we recommend creating a subdirectory at <code>/tmp</code> and then copying data to it before launching a program that will read these data. Note: a program must know where to find these data, so you generally must provide an absolute path to the file from within your program. Please be sure to clean up your data at the end of your job (using the <code>mv</code> or <code>rm</code> commands). Below is an example of how this might be done within a SLURM job:</p>
<pre class="outline"><code>#!/bin/bash
#SBATCH --ntasks=1
#SBATCH --nodes=1
#SBATCH --mem=4G
#SBATCH --time=4:00:00
#SBATCH --output=myjob.txt 
localdir=/tmp/myjob_${SLURM_JOBID}
mkdir ${localdir} # create unique directory on compute node
cp mydata.txt ${localdir} # copy data to node
./run_my_prog # run program that reads/writes to/from local disk
rm ${localdir}/mydata.txt # remove data from local disk
mv ${localdir}/output.txt ./ # move results to working directory on GPFS</code></pre>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="sockettimeout" class="section level6">
<h6>Jobs: a SLURM command fails with a socket timeout message. What's the problem?</h6>
<p>Occasionally when you attempt to run a SLURM command (e.g. <code>sbatch</code>, <code>salloc</code>, <code>squeue</code>) the command may hang for an extended period of time before failing with the following message:</p>
<pre class="outline"><code>error: slurm_receive_msg: Socket timed out on send/recv operation
error: Batch job submission failed: Socket timed out on send/recv operation</code></pre>
<p>This error results when the SLURM controller is under a high amount of stress. Avoiding this error requires all cluster users to play nice and follow cluster etiquette policies. Specifically, all cluster users are encouraged to</p>
<ol style="list-style-type: decimal">
<li>submit a large number (&gt;100) of similar jobs as job arrays (see our SLURM documentation page for examples), and</li>
<li>avoid submitting a large number (&gt;100) of short jobs (&lt; 30 minutes). Job</li>
</ol>
<p>arrays reduce the load on the scheduler because SLURM only attempts to schedule the entire array once, rather than every element within the array independently. Short jobs produce more &quot;churn&quot; within the job scheduler as it works to allocate, de-allocate, and re-allocate resources at a rapid pace. If you are running a lot of short jobs, please try to bundle multiple jobs together into a single job to put less stress on the scheduler. The socket timeout error message is generally intermittent, so if you wait a few minutes and try your SLURM command again it may complete immediately.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="disk_usage" class="section level6">
<h6>Disk space: Determining Disk Space Usage and Quotas</h6>
<p>As noted in the <a href="/?page_id=91">cluster disk policies</a>, you have both soft and hard limits on both your home and scratch directories. To help keep the system running smoothly, you should be in the habit of checking your usage level, especially since hard quota limits are definitive and, due to potential filesystem problems, we may have to either kill jobs or place temporary limits on accounts which exceed their soft limit. Please read our <a href="/?page_id=91">cluster disk policies</a> to understand disk space quotas and the FAQ on how to increase your available diskspace by <a href="#scratch_disk">using scratch space</a>, requesting a possible <a href="#tempquota">temporary quota increase</a>, or <a href="/?page_id=67#purchase">purchasing more diskspace</a>. To view your current usage and quota levels, type the command:</p>
<pre class="outline"><code>accre_storage</code></pre>
<p>For example:</p>
<p><a href="http://www.accre.vanderbilt.edu/wp-content/uploads/2017/02/accre_storage11.jpg"><img src="http://www.accre.vanderbilt.edu/wp-content/uploads/2017/02/accre_storage11-1024x147.jpg" alt="accre_storage1" class="alignnone wp-image-3273" width="581" height="84" /></a></p>
<p>The left section shows information about your current disk usage on <code>/home</code> and <code>/scratch</code>, while the right section shows your current file count usage. If you are in a group that purchases additional space on <code>/data</code>, you will see additional information below the <code>/scratch</code> line (see example below). Note that the <strong>Usage</strong> column is your current disk usage, the <strong>Quota</strong> column is a soft limit, while the <strong>Limit</strong> column is a hard limit. Definitions for soft and hard limits can be found on our <a href="/?page_id=91">cluster disk policies</a> page. If you are exceeding either your disk space or file count soft quota, the relevant line will be colored yellow, as shown in the example below. Make sure you delete (or compress) files as soon as possible in order to avoid disk I/O errors once the grace period has expired. If a line is colored red, it means you have either hit a hard quota limit, or your soft quota grace period has expired; any attempts to create additional files in the corresponding storage will result in I/O errors.</p>
<p><a href="http://www.accre.vanderbilt.edu/wp-content/uploads/2017/02/accre_storage21.jpg"><img src="http://www.accre.vanderbilt.edu/wp-content/uploads/2017/02/accre_storage21-1024x220.jpg" alt="accre_storage2" class="alignnone wp-image-3274" width="581" height="125" /></a></p>
<p>Note that <code>/home</code> and <code>/scratch</code> are generally controlled with <em>user</em> or <em>group</em> quotas, while <code>/data</code> (and occasionally <code>/scratch</code>) are controlled with <em>fileset</em> quotas. A user or group quota is based on the user or group owning a set of files, while fileset quotas are applied directly on files within a parent directory. One instance in which this distinction becomes important is when you are sharing files with a collaborator or labmate. With user-based quotas, if you copy a file into your colleague's home directory, the file will still count against your quota if the file owner is not changed. You can check the owner of a file by using the <code>ls -l</code> command. One other important detail about quota is data replication. ACCRE currently has data replication set to two for <code>/home</code> and <code>/data</code>. This means that the disk usage of a file stored in <code>/home</code> or <code>/data</code> on the cluster will be approximately twice that of a file outside the cluster. The <code>accre_storage</code> command shows you disk usage without data replication, so the output of <code>du -sh</code> (which shows you disk space of a directory or set of directories, and includes data replication) will differ from the <code>accre_storage</code> command. <code>ls -lh</code>, on the other hand, will show you file sizes without considering data replication, so it will be consistent with the output from <code>accre_storage</code>.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="dors_usage" class="section level6">
<h6>Disk space: My group has storage on DORS. How can I check our usage?</h6>
<p>From any cluster gateway execute</p>
<pre class="outline"><code>mmlsquota -j &lt;fileset name&gt; —block-size auto dors</code></pre>
<p>Typically, the fileset name is the same as your group name but may not always be.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="scratch_disk" class="section level6">
<h6>Disk space: Using scratch disk space</h6>
<p>You have disk and file allocations available for your use on both your home directory (which is backed up) and on scratch disk space (which is not backed up). To take advantage of your scratch disk space, simply <code>cd</code> to that filesystem and create your personal directory. For example:</p>
<pre class="outline"><code>cd /scratch
mkdir vunetid
chmod 700 vunetid
cd vunetid</code></pre>
<p>where vunetid is your unique VUNetID, which is also your ACCRE user id. If you are unsure what your VUNetID is, simply type <code>whoami</code> while logged into the cluster to find out. Note that the <code>chmod 700</code> command is needed to set the appropriate permissions on your scratch directory so that only you can access it. Note that some ACCRE groups also have their own private shared group <code>/scratch</code> directories.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="tempquota" class="section level6">
<h6>Disk space: If I need more disk space than this, will you temporarily grant a quota increase?</h6>
<p>We do not necessarily relax quota restrictions. It depends entirely on the details of your request and we can discuss your options. Please submit a <a href="/?page_id=369">Request Tracker</a> ticket explaining why you wish a quota change, how much space you believe you require, and how long you expect to need it. If you need more diskspace for an extended period of time you may purchase it. Please see the details of our <a href="/?page_id=67#purchase">cluster disk policies</a> then send us your <a href="/?page_id=369">request</a>.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="restoredata" class="section level6">
<h6>Disk space: Will ACCRE restore deleted or lost data?</h6>
<p>Yes. Please refer to our <a href="/?page_id=67#storage-backup">policy regarding restoring from backup</a>.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="copydata" class="section level6">
<h6>My network connection to ACCRE is really poor and I have a lot of data that I need to upload to ACCRE (or download from ACCRE). What are my options?</h6>
<p>To transfer files between your local machine and ACCRE, it is recommended to install and use FileZilla. FileZilla is a simple to use client which allows you to use the SFTP protocol to upload and download files between systems. To install FileZilla, simply go to their website and download the <a href="https://filezilla-project.org">client</a> The following is a beginner's guide to FileZilla: <a href="https://www.ostraining.com/blog/coding/filezilla-beginner/" class="uri">https://www.ostraining.com/blog/coding/filezilla-beginner/</a> If you do not want to overwrite files each time you upload a directory to the cluster then you can do the following: go to <code>Edit &gt; Settings &gt; Transfers &gt; File exists action</code> and change the <code>Uploads</code> setting to <code>Overwrite file if source is newer</code>. Changing this setting will only upload files that are newer than the copy on the remote system.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="gpu_submit" class="section level6">
<h6>GPU: How do I request a gpu node?</h6>
<p>Currently, you must belong to a &quot;GPU&quot; group, such as <code>nbody_gpu</code> to gain access to one or more gpu nodes. Use the appropriate SBATCH command to submit your job and tell SLURM you want a GPU node. For example: <code>#SBATCH -p maxwell</code> This will place your job on a node with NVIDIA Maxwell Titan X GPU cards. More details about submitting GPU jobs <a href="http://www.accre.vanderbilt.edu/?page_id=2154#gpujobs">can be found by clicking here.</a></p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="software_current" class="section level6">
<h6>Software: What research software packages are available on the cluster?</h6>
<p>Run <code>pkginfo</code> to see a comprehensive list of available software packages that can be accessed from your environment by using the <code>setpkgs</code> command.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="usr_env" class="section level6">
<h6>How do I make sure that my perl/python script is using the latest version available on the cluster?</h6>
<p>First, add the appropriate package to your environment (e.g. your <code>.bashrc</code>/<code>.cshrc</code> file) with command:</p>
<pre class="outline"><code>setpkgs -a PACKAGE_NAME</code></pre>
<p>Then, use the following line:</p>
<pre class="outline"><code>#!/usr/bin/env python (or perl)</code></pre>
<p>as the first line of your script. This automatically detects the path to the added perl/python package and use that version as the interpreter of your script.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="software_install" class="section level6">
<h6>Software: I'd like to have some software installed on the cluster. How do I go about doing that?</h6>
<p>As much as possible, ACCRE staff are glad to accommodate your needs for software. Of course, the software must be amenable to execution in the cluster environment and (if not open source) you are responsible for taking care of licensing arrangements prior to installation, as well as continued maintenance of the software license. If you'd like to explore the possibility of adding some software to our cluster environment, please submit a <a href="/?page_id=369">Request Tracker</a> ticket. Note that we in general recommend that users install software into their cluster home directories. In this way you have complete control over the version of the software, applying updates, and so on. ACCRE staff are more than happy to assist you during this process.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="R_install_source" class="section level6">
<h6>How do I install an R package from source code?</h6>
<p>R users should take a look at our <a href="http://www.accre.vanderbilt.edu/?page_id=2760">R Software Page</a> for details and best practices for using R on the ACCRE cluster. Here is an example that uses the <code>nlme</code> package. Login to the cluster, and, if you have not already done so, in your home directory create a directory for your R packages. Here is an example:</p>
<pre class="outline"><code>mkdir -p R/rlib </code></pre>
<p>You will also need a tmp directory in your home directory, so do this in your home directory:</p>
<pre class="outline"><code>mkdir tmp/ </code></pre>
<p>You will need to add both the R and the gcc compiler with <code>setpkgs</code>:</p>
<pre class="outline"><code>setpkgs -a R gcc_compiler </code></pre>
<p>Now change to your <code>tmp</code> directory, and download the source code:</p>
<pre class="outline"><code>cd tmp/ 
wget http://cran.r-project.org/src/contrib/nlme_3.1-104.tar.gz </code></pre>
<p>Generally, it will only take a few seconds to download the &quot;tarball&quot;, but sometimes it can take longer. Now start R:</p>
<pre class="outline"><code>R </code></pre>
<p>At the R-prompt (denoted by <code>&gt;</code>) tell R where you will keep your packages:</p>
<pre class="outline"><code>&gt; .libPaths(&quot;~/R/rlib&quot;) </code></pre>
<p>Next tell R to install the package:</p>
<pre class="outline"><code>&gt; install.packages(&quot;nlme_3.1-104.tar.gz&quot;, repos = NULL, type=&quot;source&quot;) </code></pre>
<p>R will now compile and install <code>nlme</code> into your personal R library: <code>~/R/rlib</code></p>
<p>To test your install quit R</p>
<pre class="outline"><code>&gt; quit()</code></pre>
<p>Restart R and at the prompt</p>
<pre class="outline"><code>&gt; .libPaths(&quot;~/R/rlib&quot;) 
&gt; library(&quot;nlme&quot;) </code></pre>
<p>You should see nlme loaded. You need to remember to add these two lines to any script you feed to R if you intend to use nlme. If you wind up installing many packages you can put the <code>.libPaths(&quot;~/R/rlib&quot;)</code> command in your <code>.Rprofile</code>. You may now delete the sourcecode package:</p>
<pre class="outline"><code>rm nlme_3.1-104.tar.gz </code></pre>
<p>What happens if R says that there are needed dependencies? This sometimes happens, and you will need to download and install those packages before installing the one you wanted. Just follow the steps outlined above until you have downloaded and installed all the packages.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="R_install_internet" class="section level6">
<h6>Software: How do I download and install an R package from the internet?</h6>
<p>R users should take a look at our <a href="http://www.accre.vanderbilt.edu/?page_id=2760">R Software Page</a> for details and best practices for using R on the ACCRE cluster. Here is an example that uses the <code>Zelig</code> package. Login to the cluster, and, if you have not already done so, in your home directory create a directory for your R packages. Here is an example:</p>
<pre class="outline"><code>mkdir -p R/rlib </code></pre>
<p>You will need to add both the R and the gcc compiler with <code>setpkgs</code>:</p>
<pre class="outline"><code>setpkgs -a R gcc_compiler </code></pre>
<p>Now start R:</p>
<pre class="outline"><code>R </code></pre>
<p>At the R-prompt (denoted by <code>&gt;</code>) tell R where you will keep your packages:</p>
<pre class="outline"><code>&gt; .libPaths(&quot;~/R/rlib&quot;) </code></pre>
<p>Next tell R to install the package:</p>
<pre class="outline"><code>&gt; install.packages(&quot;Zelig&quot;) </code></pre>
<p>R will now give you a list of repositories to download from. Choosing the Tennessee repository seems good. That is choice <code>80</code>. R will now download, compile and install Zelig into your personal R library, <code>~/R/rlib</code>.</p>
<p>To test your install, quit R</p>
<pre class="outline"><code>&gt; quit() </code></pre>
<p>Restart R and at the prompt</p>
<pre class="outline"><code>&gt; .libPaths(&quot;~/R/rlib&quot;) 
&gt; library(&quot;Zelig&quot;) </code></pre>
<p>You should see Zelig loaded. You need to remember to add these two lines to any script you feed to R if you intend to use Zelig. If you wind up installing many packages you can put the <code>.libPaths(&quot;~/R/rlib&quot;)</code> command in your <code>.Rprofile</code>.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="R_install_bioconductor" class="section level6">
<h6>Software: How do I install and load an R package from Bioconductor?</h6>
<p>R users should take a look at our <a href="http://www.accre.vanderbilt.edu/?page_id=2760">R Software Page</a> for details and best practices for using R on the ACCRE cluster. Here is an example that uses the <code>goseq</code> package. Login to the cluster, and in your home directory create a directory for your R packages. Here is an example:</p>
<pre class="outline"><code>mkdir -p R/rlib </code></pre>
<p>You will need to add both the R and the gcc compiler with <code>setpkgs</code>:</p>
<pre class="outline"><code>setpkgs -a R gcc_compiler </code></pre>
<p>Now start R:</p>
<pre class="outline"><code>R</code></pre>
<p>At the R-prompt &quot;&gt;&quot; tell R where you will keep your packages:</p>
<pre class="outline"><code>&gt; .libPaths(&quot;~/R/rlib&quot;) </code></pre>
<p>Next, point R to the Bioconductor site:</p>
<pre class="outline"><code>&gt; source(&quot;http://bioconductor.org/biocLite.R&quot;) </code></pre>
<p>Next, ask R to get the package, compile and install it in your personal R library (<code>~/R/rlib</code>)</p>
<pre class="outline"><code>&gt; biocLite(&quot;goseq&quot;) </code></pre>
<p><code>goseq</code> and its dependencies will be downloaded, compiled, and installed. If everything succeeds you will see</p>
<pre class="outline"><code>* DONE (goseq)</code></pre>
<p>After that, you may get a series of warnings about packages needing to be upgraded. You may ignore the warnings. To test your install quit R</p>
<pre class="outline"><code>&gt; quit() </code></pre>
<p>Restart R and at the prompt</p>
<pre class="outline"><code>&gt; .libPaths(&quot;~/R/rlib&quot;) 
&gt; library(&quot;goseq&quot;) </code></pre>
<p>You should see <code>goseq</code> and the two dependencies loaded. You need to remember to add these two lines to any script you feed to R if you intend to use goseq. If you wind up installing many packages from Bioconductor you can put the <code>.libPaths(&quot;~/R/rlib&quot;)</code> command in your <code>.Rprofile</code>.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="perl_module_install" class="section level6">
<h6>Software: How do I install a perl module without root privilege?</h6>
<p>You do not need to have root permission to install a module. You just install your PERL module locally in your home directory. Make a directory called, say, <code>lib/</code> in your home directory like this:</p>
<pre class="outline"><code># first navigate to your home directory 
$ cd ~ 

# now make a directory called lib 
$ mkdir lib </code></pre>
<p>Now you have a directory called <code>~/lib</code> where the <code>~</code> represents the path to your home dir. <code>~</code> literally means your home dir, but you probably know that already. All you need to do is add a modifier to your perl <code>Makefile.PL</code> command</p>
<pre class="outline"><code>$ perl Makefile.PL PREFIX=~/lib LIB=~/lib </code></pre>
<p>This tells Make to install the files in the lib directory in your home directory. You then just <code>make</code>/<code>nmake</code> as before. To use the module you just need to add <code>~/lib</code> to <code>@INC</code>. Next, you modify the top of your own scripts to look like this:</p>
<pre class="outline"><code>#!/usr/bin/perl -w use strict; # add your ~/lib dir to @INC use lib
&#39;/usr/home/your_home_dir/lib/&#39;; # proceed as usual use Some::Module;</code></pre>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="python_check_packages" class="section level6">
<h6>Software: How do I check which python packages are installed?</h6>
<p>Python users should check out our <a href="http://www.accre.vanderbilt.edu/?page_id=2702">Python Software Page</a> for tips and best practices for using Python on the ACCRE cluster. First, make sure you have loaded the correct version of python into your environment (by typing something like <code>setpkgs -a python2</code>. You can check the versions of python installed on the cluster by typing <code>pkginfo | grep python</code>). Once you have done this, next type:</p>
<pre class="outline"><code>python_pkginfo.py</code></pre>
<p>This will run a script that lists the python packages in your current environment, including any you have installed locally (see next section). <code>python_pkginfo.py</code> also accepts two optional arguments, <code>--ncol</code> (for adjusting the number of columns in the output) and <code>--type</code> (this controls whether installed packages, modules, or both are printed). For example:</p>
<pre class="outline"><code>python_pkginfo.py --ncol 3 --type both </code></pre>
<p>would list all installed packages and modules in three columns of output. By default, installed packages are output in two columns.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="python_module_install" class="section level6">
<h6>Software: How do I install a python package from source code?</h6>
<p>Python users should check out our <a href="http://www.accre.vanderbilt.edu/?page_id=2702">Python Software Page</a> for tips and best practices for using Python on the ACCRE cluster. Here is an example that uses the SQLAlchemy package. You will also need a tmp directory in your home directory, so do this in your home directory:</p>
<pre class="outline"><code>mkdir -p temp/SQLAlchemy 
cd temp/SQLAlchemy </code></pre>
<p>Download the source code, and untar it:</p>
<pre class="outline"><code>wget http://pypi.python.org/packages/source/S/SQLAlchemy/SQLAlchemy-0.7.9.tar.gz
tar xzf SQLAlchemy-0.7.9.tar.gz </code></pre>
<p>You will need to add the appropriate version of python (the example below loads python2; you can check the versions of python installed on the cluster by typing <code>pkginfo | grep python</code>) as well as the gcc compiler and the atlas library with <code>setpkgs</code>:</p>
<pre class="outline"><code>setpkgs -a python2 
setpkgs -a gcc_compiler 
setpkgs -a atlas </code></pre>
<p>Install the module:</p>
<pre class="outline"><code>cd SQLAlchemy-0.7.9 
python setup.py install --user </code></pre>
<p>This installs the package to <code>/home/YOUR.VUNETID/.local</code>. All packages installed to that directory are automatically added into the python environment.</p>
<p><a href="#top">Top of Page</a></p>
<hr />
</div>
<div id="matlab_sas_license" class="section level6">
<h6>Software: How do I run Matlab/SAS job on the cluster?</h6>
<p>In order to run Matlab/SAS jobs, you must first purchase a license from <a href="https://softwarestore.vanderbilt.edu/">ITS software store</a>. Once ITS notifies us your purchase, you will be added to the relevant group so that you can have permission to run the software. License may not be shared among different users. However, with one license, you can run multiple jobs at the same time on the cluster.</p>
<p><a href="#top">Top of Page</a></p>
</div>
</div>
